"""
é å…ˆä¸‹è¼‰ä¸¦è½‰å­˜æ‰€æœ‰æ¨¡å‹ï¼Œä½¿ backend å¯é›¢ç·šå•Ÿå‹•ã€‚
åŒ…å«ï¼š
 - TinyLlama (LLM)
 - all-MiniLM-L6-v2 (Embedder)
 - Phi-3.5-mini-instruct (Graph Extractor)
"""

from transformers import AutoTokenizer, AutoModelForCausalLM
from sentence_transformers import SentenceTransformer
from pathlib import Path

MODELS_DIR = Path(__file__).resolve().parents[1] / "models"
MODELS_DIR.mkdir(parents=True, exist_ok=True)


def prefetch_llm():
    model_id = "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
    target = MODELS_DIR / "llm"
    target.mkdir(parents=True, exist_ok=True)

    print(f"ğŸ¦™ ä¸‹è¼‰ LLMï¼š{model_id}")
    AutoModelForCausalLM.from_pretrained(model_id, cache_dir=target)
    AutoTokenizer.from_pretrained(model_id, cache_dir=target)
    print(f"âœ… LLM å·²å¿«å–è‡³ {target}")


def prefetch_embedder():
    model_id = "sentence-transformers/all-MiniLM-L6-v2"
    target = MODELS_DIR / "embedder"
    target.mkdir(parents=True, exist_ok=True)

    print(f"ğŸ”¤ ä¸‹è¼‰ Embedderï¼š{model_id}")
    # ä½¿ç”¨ SentenceTransformers å®˜æ–¹ API ä¸‹è¼‰ä¸¦è½‰å­˜æˆå¯ç›´æ¥è¼‰å…¥çš„æ ¼å¼
    model = SentenceTransformer(model_id)
    model.save(str(target))
    print(f"âœ… Embedder å·²ä¿å­˜ç‚ºå¯ç›´æ¥è¼‰å…¥æ ¼å¼æ–¼ {target}")


def prefetch_graph_extractor():
    model_id = "microsoft/Phi-3.5-mini-instruct"
    target = MODELS_DIR / "graph_extractor"
    target.mkdir(parents=True, exist_ok=True)

    print(f"ğŸ§  ä¸‹è¼‰ Graph Extractorï¼š{model_id}")
    AutoModelForCausalLM.from_pretrained(model_id, cache_dir=target)
    AutoTokenizer.from_pretrained(model_id, cache_dir=target)
    print(f"âœ… Graph Extractor å·²å¿«å–è‡³ {target}")


if __name__ == "__main__":
    print("ğŸš€ é–‹å§‹é ä¸‹è¼‰æ‰€æœ‰æ¨¡å‹ ...")
    prefetch_llm()
    prefetch_embedder()
    prefetch_graph_extractor()
    print("ğŸ‰ æ‰€æœ‰æ¨¡å‹å·²æº–å‚™å®Œæˆï¼Œå¯é›¢ç·šå•Ÿå‹•ï¼")
