from __future__ import annotations

import json
import re
from typing import Any, Dict, List, Optional, Protocol

from app.capabilities.textgen.text_generator import TextGenerator
from app.core.llm.llm import LLM
from app.core.graph.graph_store import Triple

class GraphExtractor:
    """
    GraphExtractor
    -----------------
    åŸºæ–¼ LLM çš„ä¸‰å…ƒçµ„æŠ½å–æ¨¡çµ„ã€‚

    è·è²¬ï¼š
    - çµ„ prompt
    - å‘¼å« LLM
    - å˜—è©¦è§£æ JSON / åŠçµæ§‹è¼¸å‡º
    - æ­£è¦åŒ–ç‚ºç³»çµ±å…§ä½¿ç”¨çš„ Triple çµæ§‹
    """

    def __init__(
        self,
        llm: TextGenerator,
        max_input_chars: int = 400,
    ) -> None:
        self._generate = llm.generate
        self.max_input_chars: int = max_input_chars


    # ----------------------------------------------------------
    # ä¸‰å…ƒçµ„æŠ½å–
    # ----------------------------------------------------------
    def extract_triples(self, text: str) -> List[Triple]:
        """
        å¾è¼¸å…¥æ–‡å­—ä¸­æŠ½å–æ‰€æœ‰ (subject, predicate, object) ä¸‰å…ƒçµ„ã€‚

        Args:
            text: åŸå§‹è¼¸å…¥æ–‡å­—ã€‚

        Returns:
            æ­£è¦åŒ–å¾Œçš„ Triple æ¸…å–®ã€‚
        """
        truncated_text: str = text[: self.max_input_chars]

        prompt = f"""
æˆ‘è¦åšçŸ¥è­˜åœ–è­œ, è«‹å¹«æˆ‘æ‰¾ä¸‰å…ƒçµ„. åªè¼¸å‡º JSON é™£åˆ—.
æ ¼å¼ç‚º[{{"subject":"","predicate":"","object":""}}]
è«‹ç”¨ç¹é«”ä¸­æ–‡ã€‚
ä¸è¦çµ¦jsonä»¥å¤–çš„æè¿°.
objectæ˜¯é€£æ¥è©çš„æ„æ€.

æ–‡å­—å¦‚ä¸‹ï¼š
{truncated_text.strip()}

è«‹è¼¸å‡ºçµæœï¼š
        """

        try:
            result: str = self._generate(prompt)[0]["generated_text"]
            triples = self._parse_triples(result)
            print(f"ğŸ“Š GraphExtractorï¼šè§£æåˆ° {len(triples)} å€‹ä¸‰å…ƒçµ„ã€‚")
            return triples
        except Exception as e:
            print(f"âŒ GraphExtractor æŠ½å–å¤±æ•—: {e}")
            return []

    # ----------------------------------------------------------
    # è¼”åŠ©ï¼šè§£æ JSON / é¡ JSON
    # ----------------------------------------------------------
    def _parse_triples(self, text: str) -> List[Triple]:
        """
        å˜—è©¦è§£ææ¨¡å‹è¼¸å‡ºçš„ JSON æˆ–åŠçµæ§‹æ–‡å­—ã€‚

        Args:
            text: LLM åŸå§‹è¼¸å‡ºã€‚

        Returns:
            æ­£è¦åŒ–å¾Œçš„ Triple æ¸…å–®ã€‚
        """
        raw_triples: List[dict[str, Any]] = []

        # 1ï¸âƒ£ ç›´æ¥ JSON
        try:
            parsed = json.loads(text)
            if isinstance(parsed, list):
                raw_triples = parsed
        except Exception:
            pass

        # 2ï¸âƒ£ æ“·å–æœ€å¾Œä¸€æ®µ JSON é™£åˆ—
        if not raw_triples:
            matches = re.findall(r"\[[\s\S]*?\]", text)
            for candidate in reversed(matches):
                try:
                    parsed = json.loads(candidate)
                    if isinstance(parsed, list):
                        raw_triples = parsed
                        break
                except Exception:
                    continue

        # 3ï¸âƒ£ fallbackï¼šè‡ªç„¶èªè¨€çŒœæ¸¬ï¼ˆä¿å®ˆï¼‰
        if not raw_triples:
            lines = re.findall(r"(.+?)\s*[ï¼Œ,ã€‚]\s*", text)
            for line in lines:
                if any(kw in line for kw in ("æ³¨æ„", "æ ¼å¼", "ç¯„ä¾‹", "èªªæ˜")):
                    continue
                if "ï¼š" in line:
                    left, right = line.split("ï¼š", 1)
                    raw_triples.append(
                        {
                            "subject": left.strip(),
                            "predicate": "æè¿°",
                            "object": right.strip(),
                        }
                    )

        return self._normalize_triples(raw_triples)

    # ----------------------------------------------------------
    # æ­£è¦åŒ–
    # ----------------------------------------------------------
    def _normalize_triples(
        self,
        triples: List[dict[str, Any]],
    ) -> List[Triple]:
        """
        å°‡åŸå§‹è§£æçµæœæ­£è¦åŒ–ç‚ºç³»çµ±å…§çš„ Tripleã€‚

        Args:
            triples: å°šæœªä¿è­‰çµæ§‹æ­£ç¢ºçš„ä¸‰å…ƒçµ„è³‡æ–™ã€‚

        Returns:
            æ­£è¦åŒ–å¾Œçš„ Triple æ¸…å–®ã€‚
        """
        normalized: List[Triple] = []

        for t in triples:
            s = t.get("subject")
            p = t.get("predicate")
            o = t.get("object")

            if not s or not p:
                continue

            # â­ object ç¼ºå¤±æ™‚çš„ä¿å®ˆ fallback
            if not o:
                o = p
                p = "éš±å«"

            normalized.append(
                {
                    "subject": str(s).strip(),
                    "predicate": str(p).strip(),
                    "object": str(o).strip(),
                }
            )

        return normalized

    # ----------------------------------------------------------
    # è¼”åŠ©ï¼šå¥å­æ˜¯å¦åƒã€Œé—œä¿‚æè¿°ã€
    # ----------------------------------------------------------
    def looks_like_relation(self, text: str) -> bool:
        """
        åˆ¤æ–·ä¸€å¥è©±æ˜¯å¦çœ‹èµ·ä¾†åœ¨æè¿°å¯¦é«”é—œä¿‚ã€‚
        ç”¨æ–¼ GraphBuilder çš„æ’åºå„ªå…ˆåº¦ã€‚

        Args:
            text: è¼¸å…¥å¥å­ã€‚

        Returns:
            æ˜¯å¦åƒé—œä¿‚å¥ã€‚
        """
        if not text:
            return False

        t = text.strip()

        if len(t) < 4 or len(t) > self.max_input_chars:
            return False

        relation_keywords = [
            "æ˜¯", "ç‚º", "å±¬æ–¼", "åŒ…å«", "æ“æœ‰", "ä½æ–¼", "å°è‡´", "é€ æˆ", "ä»£è¡¨",
            "ä½¿ç”¨", "éœ€è¦", "æä¾›", "ç­‰æ–¼", "æ„å‘³è‘—", "ç”±", "ç”¢ç”Ÿ", "æè¿°", "ç¨±ç‚º",
            "é—œæ–¼", "åŒ…æ‹¬", "å½¢æˆ", "æ§‹æˆ", "ä¾è³´", "æ ¹æ“š", "åŒ…å«æ–¼",
        ]

        keyword_hit: bool = any(k in t for k in relation_keywords)
        multi_entity_like: bool = bool(
            re.search(r"[\u4e00-\u9fff]{2,}.+[\u4e00-\u9fff]{2,}", t)
        )

        if t.endswith(("ï¼Ÿ", "!", "ï¼")):
            return False

        return keyword_hit and multi_entity_like
